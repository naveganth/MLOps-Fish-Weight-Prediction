# üêü Fish Weight Prediction - End-to-End MLOps

Este projeto √© uma solu√ß√£o completa de Machine Learning para prever o peso de peixes com base em medidas f√≠sicas. O objetivo foi demonstrar boas pr√°ticas de MLOps, desde a engenharia de dados at√© o deploy de uma API escal√°vel e interface de usu√°rio.

## üéØ O Desafio

Desenvolver um pipeline reprodut√≠vel para treinar um modelo de regress√£o (**XGBoost**), versionar artefatos e disponibilizar o modelo para infer√™ncia via API e Docker.

## üèó Arquitetura da Solu√ß√£o

O projeto est√° modularizado para garantir separa√ß√£o de responsabilidades:

- **Feature Pipeline:** Ingest√£o, limpeza e transforma√ß√£o dos dados (`src/feature_pipeline`).
- **Training Pipeline:** Treinamento do modelo XGBoost com rastreamento de m√©tricas via MLflow (`src/training_pipeline`).
- **Inference:** API REST de alto desempenho com FastAPI.
- **Frontend:** Interface interativa com Streamlit para testes manuais.
- **Infraestrutura:** Containeriza√ß√£o com Docker e automa√ß√£o via Makefile.
- **CI/CD:** Pipeline de testes automatizados via GitHub Actions.

## üìÇ Estrutura do Projeto

```text
‚îú‚îÄ‚îÄ .github/workflows  # Pipeline de CI (Testes e Build)
‚îú‚îÄ‚îÄ data/              # Dados brutos e processados
‚îú‚îÄ‚îÄ models/            # Artefatos do modelo (.pkl)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/           # C√≥digo da API (FastAPI)
‚îÇ   ‚îú‚îÄ‚îÄ feature_.../   # Scripts de processamento
‚îÇ   ‚îú‚îÄ‚îÄ training_.../  # Scripts de treino e tuning
‚îÇ   ‚îî‚îÄ‚îÄ app.py         # Frontend Streamlit
‚îú‚îÄ‚îÄ tests/             # Testes unit√°rios e de integra√ß√£o
‚îú‚îÄ‚îÄ Dockerfile         # Configura√ß√£o da imagem da API
‚îú‚îÄ‚îÄ Makefile           # Comandos r√°pidos de execu√ß√£o
‚îî‚îÄ‚îÄ pyproject.toml     # Depend√™ncias (gerenciado pelo uv)
```

## üöÄ Como Executar

### Pr√©-requisitos

- **Docker** (Recomendado para execu√ß√£o isolada)
- Ou **Python 3.11+** com `uv` instalado para execu√ß√£o local.

---

### Op√ß√£o 1: Via Docker (Recomendado üê≥)

Esta op√ß√£o sobe a API pronta para uso sem instalar nada no seu Python local.

**1. Construir e Rodar a API:**
Isso ir√° construir a imagem, remover containers antigos e iniciar a API na porta 8000.

```bash
make docker-auto
```

**2. Testar a API:**

- Acesse a documenta√ß√£o interativa (Swagger): [http://localhost:8000/docs](https://www.google.com/search?q=http://localhost:8000/docs)
- Ou veja a se√ß√£o **"Como Realizar a Infer√™ncia"** abaixo.

---

### Op√ß√£o 2: Execu√ß√£o Local (Desenvolvimento)

Se preferir rodar os scripts manualmente:

**1. Instalar depend√™ncias:**

```bash
pip install uv
make install
```

**2. Treinar o Modelo:**
Executa o pipeline completo (Load -\> Preprocess -\> Feature Eng -\> Train). O modelo ser√° salvo em `models/xgb_model.pkl` e as m√©tricas registradas no MLflow.

```bash
make train
```

**3. Rodar a API:**

```bash
make run-api
```

**4. Rodar o Dashboard (Streamlit):**
Para visualizar uma interface gr√°fica amig√°vel:

```bash
make run-app
```

- Acesse em: [http://localhost:8501](https://www.google.com/search?q=http://localhost:8501)

## üì° Como Realizar a Infer√™ncia

A API aceita requisi√ß√µes POST no endpoint `/predict`. Abaixo est√£o exemplos de como testar.

**Exemplo de Payload (JSON):**

```json
[
  {
    "Species": "Perch",
    "Length1": 20.0,
    "Length2": 22.0,
    "Length3": 23.5,
    "Height": 5.5,
    "Width": 3.3
  }
]
```

**Comando cURL:**

```bash
curl -X 'POST' \
  'http://localhost:8000/predict' \
  -H 'Content-Type: application/json' \
  -d '[{"Species": "Perch", "Length1": 20.0, "Length2": 22.0, "Length3": 23.5, "Height": 5.5, "Width": 3.3}]'
```

**Resposta Esperada:**

```json
{
  "predictions": [245.32]
}
```

## ‚úÖ Checklist de Entregas

### Requisitos Obrigat√≥rios

- [x] **Python + ML:** Modelo XGBoost treinado com separa√ß√£o clara de pipelines.
- [x] **Pipeline de MLOps:** Versionamento de modelos com MLflow e scripts modulares.
- [x] **Deploy:** API servida via Container Docker.
- [x] **README:** Documenta√ß√£o completa da arquitetura e execu√ß√£o.

### Diferenciais Implementados (Opcionais)

- [x] **Testes Unit√°rios:** Cobertura de testes com pytest (API, Schema e Infer√™ncia).
- [x] **CI/CD:** Pipeline no GitHub Actions para testes e build autom√°tico.
- [x] **Makefile:** Automa√ß√£o de comandos para facilitar a execu√ß√£o.
- [x] **Model Registry:** Integra√ß√£o com MLflow para rastreamento de experimentos.
- [x] **Visualiza√ß√£o:** Aplica√ß√£o Fullstack com Streamlit.

## üîÆ Poss√≠veis Melhorias

Pontos identificados para evolu√ß√£o futura do projeto:

- **Monitoramento de Drift:** Integra√ß√£o com EvidentlyAI para alertar se os peixes na infer√™ncia tiverem medidas muito diferentes do treino.
- **Deploy em Cloud:** Configura√ß√£o de deploy cont√≠nuo (CD) para AWS ECS ou Lambda utilizando Terraform.
- **Feature Store:** Para um cen√°rio com milh√µes de registros, implementar uma Feature Store (ex: Feast) para servir features pr√©-calculadas.
- **Autentica√ß√£o:** Adicionar camada de seguran√ßa (OAuth2) na API.

---

**Autor:** [Seu Nome]

---
